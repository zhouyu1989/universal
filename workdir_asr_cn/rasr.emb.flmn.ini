[config]
using_ini_dir=1
logging_config_file=logging.conf

[lm]
# 通用领域语言模型
general=
# 专用领域语言模型
#specific=
# 离线编译好的固定语法网络
const_grammars=
read_fst_use_mmap=0

wfst_symbol_table        =
# 符号表的发音词典
wfst_symbol2phones_table =
# 用于语法网络的辅助语言模型
wfst_lex_lm              =
# 语法网络里的空弧id数目，至少为1，小于这个数目的id都认为是空弧，这个数目等于上面发音词典里同音字（词）的最大数目+1，此处配置是为了校验用。
wfst_eps_number          = 1

[am]
# 模型所在的位置
path         = model/20180917_ruoqi_flmn/rokid.npu
# 模型类型，0代表dynamic rnn，1代表static rnn。
model_type   = 0
# 先验概率
#prior_lm     = model/emb/reflm.1gram.txt
# 声学输出的符号表
symbol_table = model/20180917_ruoqi_flmn/symbol_table.txt

# 模型输入输出参数
input_flags_name=flags
input_fe_ctx_name=ctxcnn0
input_fe_name=spectros
#input_ctx_names=ctxcnn1,ctxcnn2,rnnstates
#output_names=out_ctxcnn1,out_ctxcnn2,out_rnnstates,postprobs
input_ctx_names=ctxcnn1,ctxcnn2,ctxflmn0,ctxflmn1,ctxflmn2,ctxflmn3,ctxflmn4
output_names=out_ctxcnn1,out_ctxcnn2,out_ctxflmn0,out_ctxflmn1,out_ctxflmn2,out_ctxflmn3,out_ctxflmn4,postprobs

input_frame_dim=40
output_frame_dim=436
first_frame_num=15
batch_frame_num=4
min_batch_bundle_num=2
ctx_frame_num=2

# 是否以固定输入输出的方式工作。0代表动态输入长度；否则的话，等于固定输入的frame数目。
fixed_input_frames=8
# 固定输出多少frame，用于校验。
fixed_output_frames=2

# 是否启用batch模式。batch模式会内部启动worker线程，批量处理模型计算请求。
batch_mode=1
# batch的最大尺寸
batch_size=8
# 每个batch最大处理的总frame数
batch_max_frames=100
# 启动多少个worker线程
worker_num=1
# 是否需要手动batch处理控制。主要用于前端。
manual_batch_step=1
# 是否把每个batch都pad到最大尺寸。主要用于前端。
pad_batch=0
double_buffer=0
# 是否打印声学计算的batch时间统计信息
debug_print_batch_log=0

# TensorFlow的session配置参数（字节形式的protobuffer）
# 04 means using 4 threads (arm cores)
tfrtl_config_env=10 08


[fe]
feature_type=0
frame_length_ms=25
frame_shift_ms=10
dither=0.0
fbank_num=40
low_freq=100
high_freq=7800


[asr]
use_single_ac_path=1
# 先验概率的缩放系数，范围：0.5 - 1.3
prior_scale=0.6
# 通用语言模型的缩放系数，范围：0.5 - 1.3
general_lm_scale=0.8
# 专用语言模型的缩放系数，范围：0.5 - 1.3
specific_lm_scale=0.8
grammar_scale=1.0
# 声学得分的缩放系数，范围：0.5 - 1.3
am_scale=1.0

# 声学的beam宽度（路径数目）
beam_width=10
# 声学路径的最大差值，<=0.0表示无限制
ac_beam=5.0
# 最多选择多少声学输出符号
label_selection_size=15
# 声学输出的动态范围选择
label_selection_margin=6.0
# 控制连续blank的解码策略
blank_selection_score=-0.01
blank_selection_repeat=5
# 是否在lm解码过程中采用平均概率策略
lm_use_avg_prob=0

# 解码网络的路径数目
wfst_max_active=300
# grammar解码网络的路径数目
wfst_grammar_max_active=300
wfst_min_active=1
# 解码网络的beam限制
wfst_beam=15.0
wfst_beam_delta=0.5
wfst_hash_ratio=2.0

add_final_to_start_epsilon=0
final_to_start_weight=4.0

# 是否启用vad start检测
auto_start=0
# 是否启用vad stop检测
auto_stop=0
# 是否自动开始新的识别
auto_restart=0
# vad的最小能量限制
vad_min_energy=300
# 是否启用vad的pitch检测
vad_enable_pitch=0
# vad begin的最小pitch frame数目
vad_begin_pitch=1
# vad end的最小pitch frame数目
vad_end_pitch=1
# vad往前多加多少毫秒
vad_pre_ms=100
# vad begin的窗口大小
vad_begin_ms=300
# vad end的 窗口大小
vad_end_ms=500
# 连续输出blank就stop的窗口大小
blank_end_ms=1000
# 最大一次识别多少时间
max_end_ms=3000
skip_end_step_num=0

# 是否工作在持续识别模式
endless_mode=1

wave_buf_init_ms=10000
wave_buf_max_sec=3600
wave_buf_max_block_ms=5000

# 是否默认启用整包识别
whole_wave_reco=1

# 关键发音的阈值调整
keyprons=ruo qi|0.6|mei shi le|-0.5|mei shi la|-0.5|ruo ji|-1.5|ruo xi|-1.5|le qi|-2.0|ruo qing|-1.0|re qing|-0.5|wu ji|-1.0|er qie|-1.0|mo xi|-2.0|lao tie|-1.5
keypron_begin_val=0.0
keypron_margin_cost=-0.2
#localcmd_fst=model/emb/instgram.fst

grammar_use_prior=1
grammar_arc_weight=1.2
grammar_margin_cost=-0.3

# 是否返回中间结果
ret_temp_result=1
ret_temp_interval_ms=40
# 返回结果的内容：0 拼音，1 文字，2 拼音/文字
ret_wfst_result=2
ret_keyprons_only=0
# 返回结果的个数
nbest_result_number=1
# 返回结果的统计信息：0 不返回，1 返回“结果/识别器/fst/时间”, 2 返回“结果/识别器/fst/时间/最高分”
result_with_stat=2
ret_final_only=0

# 是否返回每个frame的声学得分
debug_print_frame_scores=0
debug_print_frame_nbests=0
debug_print_user_grammars=1
debug_print_decoder_stats=0
debug_save_log_waves=0
